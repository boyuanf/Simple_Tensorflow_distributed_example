{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create with job name localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "c = tf.constant(\"Hello from server1!\")\n",
    "\n",
    "# 生成一个有两个任务的集群，一个任务跑在本地2222端口，另外一个跑在本地2223端口。\n",
    "cluster = tf.train.ClusterSpec(\n",
    "    {\"local\": [\"localhost:2222\", \"localhost: 2223\", \"localhost: 2224\"]})\n",
    "# 通过上面生成的集群配置生成Server，并通过job_name和task_index指定当前所启动\n",
    "# 的任务。因为该任务是第一个任务，所以task_index为0。\n",
    "server = tf.train.Server(cluster, job_name=\"local\", task_index=0)\n",
    "\n",
    "# 通过server.target生成会话来使用TensorFlow集群中的资源。通过设置\n",
    "# log_device_placement可以看到执行每一个操作的任务。\n",
    "sess = tf.Session(\n",
    "    server.target, config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess.run(c))\n",
    "server.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.device(\"/job:local/task:1\"):\n",
    "    c = tf.constant(\"Hello from server2!\")\n",
    "\n",
    "# 和第一个程序一样的集群配置。集群中的每一个任务需要采用相同的配置。\n",
    "cluster = tf.train.ClusterSpec(\n",
    "    {\"local\": [\"localhost:2222\", \"localhost: 2223\", \"localhost: 2224\"]})\n",
    "# 指定task_index为1，所以这个程序将在localhost:2223启动服务。\n",
    "server = tf.train.Server(cluster, job_name=\"local\", task_index=1)\n",
    "# 剩下的代码都和第一个任务的代码一致。\n",
    "sess = tf.Session(\n",
    "    server.target, config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess.run(c))\n",
    "server.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 和第一个程序一样的集群配置。集群中的每一个任务需要采用相同的配置。\n",
    "cluster = tf.train.ClusterSpec(\n",
    "    {\"local\": [\"localhost:2222\", \"localhost: 2223\", \"localhost: 2224\"]})\n",
    "# 指定task_index为2，所以这个程序将在localhost:2224启动服务。\n",
    "server = tf.train.Server(cluster, job_name=\"local\", task_index=2)\n",
    "\n",
    "server.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three local server will begin to run, after execute the above code indivadually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the following script on any of the server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(1.0)\n",
    "b = a + 2\n",
    "c = a * 3\n",
    "\n",
    "# set \"grpc://localhost: 2224\" , means the session will execute on machine3, however,\n",
    "# it may not use the job on that machine (a, b, c all executed using task0),\n",
    "# as Tensorflow will optimize assign the resource at the cluster level\n",
    "with tf.Session(\"grpc://localhost: 2224\", config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.device(\"/job:local/task:1/cpu:0\"):\n",
    "    a = tf.constant(1.0)\n",
    "\n",
    "with tf.device(\"/job:local/task:2/cpu:0\"):\n",
    "    b = a + 2\n",
    "\n",
    "c = a * 3\n",
    "\n",
    "# set \"grpc://localhost: 2223\" , means the session will execute on machine2, however,\n",
    "# it runs on the device that we specific above: a on task0, b on task12, c on task1(auto assigned)\n",
    "with tf.Session(\"grpc://localhost: 2223\", config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the tf.Variable and tf.get_variable are shared across the servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run following code with \"grpc://localhost:2223 init\" as parameter will create the variable, and run with parameter \"grpc://localhost:2224\" will just reuse the variable we create on different server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_client.py\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "#x = tf.Variable(0.0, name=\"x\")\n",
    "x = tf.get_variable(\"x\", dtype=tf.float32, initializer=0.0)\n",
    "increment_x = tf.assign(x, x+1)\n",
    "\n",
    "with tf.Session(sys.argv[1], config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    if sys.argv[2:] == [\"init\"]:\n",
    "        sess.run(x.initializer)\n",
    "    sess.run(increment_x)\n",
    "    print(x.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create with job name ps and worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job name ps and worker also works for the localhost, the following create three localhost servers with jobname ps and worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cluster_spec = {\n",
    "    \"ps\": [\"localhost:2222\"],\n",
    "    \"worker\": [\"localhost:2223\", \"localhost:2224\"]}\n",
    "server = tf.train.Server(cluster_spec, job_name=\"ps\", task_index=0)\n",
    "\n",
    "c = tf.constant(\"Hello from server1!\")\n",
    "with tf.device(tf.train.replica_device_setter(cluster=cluster_spec)):\n",
    "  v = tf.get_variable(\"v\", shape=[20, 20])  # this variable is placed\n",
    "                                            # in the parameter server\n",
    "                                            # by the replica_device_setter\n",
    "\n",
    "sess = tf.Session(\n",
    "    server.target, config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess.run(c))\n",
    "sess.run(v.initializer)\n",
    "sess.run(v)\n",
    "server.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cluster_spec = {\n",
    "    \"ps\": [\"localhost:2222\"],\n",
    "    \"worker\": [\"localhost:2223\", \"localhost:2224\"]}\n",
    "server = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=0)\n",
    "\n",
    "server.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cluster_spec = {\n",
    "    \"ps\": [\"localhost:2222\"],\n",
    "    \"worker\": [\"localhost:2223\", \"localhost:2224\"]}\n",
    "server = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=1)\n",
    "\n",
    "server.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
